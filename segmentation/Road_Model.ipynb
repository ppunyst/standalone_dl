{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Road_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyF9_dwitZ9A",
        "outputId": "da656e31-3835-4072-df8b-f6814178d1cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syUG5nwJtvbn"
      },
      "source": [
        "dir = '/content/drive/My Drive/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYgCBd5kkde2"
      },
      "source": [
        "# Dataset & DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd2dyL_YtK63"
      },
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as F"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoUqV5VCkgbH"
      },
      "source": [
        "class RoadDataset(Dataset):\n",
        "    def __init__(self, args, split, img_transform, label_transform):\n",
        "        self.args = args\n",
        "        self.data_dir = dir\n",
        "        self.split = split\n",
        "        self.targets = []\n",
        "\n",
        "        if self.split == \"valid\":\n",
        "            self.sample_dir = os.path.join(self.data_dir, \"train\")\n",
        "        else:\n",
        "            self.sample_dir = os.path.join(self.data_dir, split)\n",
        "\n",
        "        self.input_files = glob.glob(os.path.join(self.sample_dir, \"samples/*png\"))\n",
        "        self.target_files = glob.glob(os.path.join(self.sample_dir, \"targets/*json\"))\n",
        "\n",
        "        for f in self.target_files:\n",
        "            img = os.path.join(self.sample_dir, \"samples\", os.path.splitext(os.path.basename(f))[0] + \".png\")\n",
        "            assert os.path.isfile(img)\n",
        "            self.targets.append([f, img])\n",
        "        self.targets.sort()\n",
        "\n",
        "        if self.split == 'train':\n",
        "            self.input_files = self.input_files[:-int(len(self.input_files) * self.args.valid_ratio)]\n",
        "            self.targets = self.targets[:-int(len(self.targets) * self.args.valid_ratio)]\n",
        "\n",
        "        elif self.split == 'valid':\n",
        "            self.input_files = self.input_files[-int(len(self.input_files) * self.args.valid_ratio):]\n",
        "            self.targets = self.targets[-int(len(self.targets) * self.args.valid_ratio):]\n",
        "\n",
        "        self.img_transform = img_transform\n",
        "        self.label_transform = label_transform\n",
        "    \n",
        "        self.road_colorbook = {\"Mortorway\":(51, 51, 255),\n",
        "                               \"Primary\":(51, 255, 255), \n",
        "                               \"Secondary\":(51, 255, 51), \n",
        "                               \"Tertiary\":(255, 255, 51), \n",
        "                               \"Residential\":(255, 51, 51), \n",
        "                               \"Unclassified\":(255, 51, 255), \n",
        "                               \"background\":(0, 0, 0)}\n",
        "\n",
        "        self.road_class_id = {\"Mortorway\":1, \n",
        "                              \"Primary\":2, \n",
        "                              \"Secondary\":3, \n",
        "                              \"Tertiary\":4, \n",
        "                              \"Residential\":5, \n",
        "                              \"Unclassified\":6, \n",
        "                              \"background\":0}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.input_files[idx]\n",
        "        with open(self.targets[idx][0], \"r\") as jfile:\n",
        "            meta = json.load(jfile)\n",
        "        y = self.make_mask((1024, 1024), meta)\n",
        "        img = Image.open(X)\n",
        "        # mask = Image.open(y)\n",
        "\n",
        "        if self.img_transform:\n",
        "            image = self.img_transform(img)\n",
        "            mask = self.label_transform(y)\n",
        "        \n",
        "        return image, mask\n",
        "        \n",
        "    def make_mask(self, size, label):\n",
        "        mask = np.zeros([size[0], size[1]], dtype=np.uint8)\n",
        "        for r in range(len(label[\"features\"])):\n",
        "            road = label[\"features\"][r][\"properties\"]\n",
        "            type_name = road[\"type_name\"]\n",
        "            temp = road[\"road_imcoords\"].split(\",\")\n",
        "            coords = np.array([int(round(float(c))) for c in temp]).reshape(-1, 2)\n",
        "            cv2.fillPoly(mask, [coords], self.road_class_id[type_name])\n",
        "        return mask\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNUuNXPfNHdy",
        "outputId": "19f65157-cca7-4f20-b3a2-b03984630514"
      },
      "source": [
        "# import argparse\n",
        "# parser = argparse.ArgumentParser(description='PyTorch Semantic Segmentation Training')\n",
        "# args = parser.parse_args('')\n",
        "# args.valid_ratio = 0.5\n",
        "\n",
        "# img_trans = transforms.Compose([transforms.Resize((512, 512)),\n",
        "#                                 transforms.ToTensor()])\n",
        "# label_trans = transforms.Compose([transforms.ToPILImage(),\n",
        "#                                   transforms.Resize((512, 512)),\n",
        "#                                   transforms.PILToTensor()])\n",
        "\n",
        "# trainset = RoadDataset(args=args, split='train', img_transform=img_trans, label_transform=label_trans)\n",
        "# train_loader = DataLoader(trainset, batch_size=2)\n",
        "\n",
        "# samples, targets = next(iter(train_loader))\n",
        "# print(samples.shape, targets.squeeze(1).shape)\n",
        "# print(np.unique(targets))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 512, 512]) torch.Size([2, 512, 512])\n",
            "[0 1 2 3 4 5 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z75ZLbnsUmzP"
      },
      "source": [
        "def make_data_loaders(args):\n",
        "\n",
        "    img_trans = transforms.Compose([transforms.Resize((512, 512)),\n",
        "                                    transforms.ToTensor()])\n",
        "    label_trans = transforms.Compose([transforms.ToPILImage(),\n",
        "                                      transforms.Resize((512, 512)),\n",
        "                                      transforms.PILToTensor()])\n",
        "\n",
        "    trainset = RoadDataset(args=args, split='train', img_transform=img_trans, label_transform=label_trans)\n",
        "    validset = RoadDataset(args=args, split='valid', img_transform=img_trans, label_transform=label_trans)\n",
        "    testset = RoadDataset(args=args, split='test', img_transform=img_trans, label_transform=label_trans)\n",
        "\n",
        "    train_loader = DataLoader(trainset,\n",
        "                              batch_size=args.batch_size,\n",
        "                              pin_memory=True)\n",
        "\n",
        "    valid_loader = DataLoader(validset,\n",
        "                              batch_size=args.batch_size,\n",
        "                              pin_memory=True)\n",
        "\n",
        "    test_loader = DataLoader(testset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             pin_memory=True)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN5LLp_jU1T6",
        "outputId": "97453b90-69a0-4fde-da1e-0528927bfe1f"
      },
      "source": [
        "# import argparse\n",
        "# parser = argparse.ArgumentParser(description='PyTorch Semantic Segmentation Training')\n",
        "# args = parser.parse_args('')\n",
        "# args.valid_ratio = 0.5\n",
        "# args.batch_size = 2\n",
        "\n",
        "# train_loader, valid_loader, test_loader = make_data_loaders(args)\n",
        "\n",
        "# samples, targets = next(iter(train_loader))\n",
        "# print(samples.shape, targets.squeeze(1).shape)\n",
        "# samples, targets = next(iter(valid_loader))\n",
        "# print(samples.shape, targets.squeeze(1).shape)\n",
        "# samples, targets = next(iter(test_loader))\n",
        "# print(samples.shape, targets.squeeze(1).shape)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 512, 512]) torch.Size([2, 512, 512])\n",
            "torch.Size([2, 3, 512, 512]) torch.Size([2, 512, 512])\n",
            "torch.Size([2, 3, 512, 512]) torch.Size([2, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ByfVE_VBTy"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTF1eV7vU_wi"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZKGCfRwVEoL"
      },
      "source": [
        "def load_segmentation_models(model_name, num_class):\n",
        "\n",
        "    if model_name == 'fcn8':\n",
        "        return FCN8s(n_class=num_class)\n",
        "    elif model_name == 'fcn16':\n",
        "        return FCN16s(n_class=num_class)\n",
        "    elif model_name == 'fcn32':\n",
        "        return FCN32s(n_class=num_class)\n",
        "    elif model_name == 'unet':\n",
        "        return unet(num_classes=num_class)\n",
        "    elif model_name == 'segnet':\n",
        "        return SegNet(num_classes=num_class)\n",
        "    \n",
        "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
        "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
        "    factor = (kernel_size + 1) // 2\n",
        "    if kernel_size % 2 == 1:\n",
        "        center = factor - 1\n",
        "    else:\n",
        "        center = factor - 0.5\n",
        "    og = np.ogrid[:kernel_size, :kernel_size]\n",
        "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
        "           (1 - abs(og[1] - center) / factor)\n",
        "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
        "                      dtype=np.float64)\n",
        "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
        "    return torch.from_numpy(weight).float()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpjx3dZDVMD4"
      },
      "source": [
        "class FCN32s(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=6):\n",
        "        super(FCN32s, self).__init__()\n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32,\n",
        "                                          bias=False)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.zero_()\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                assert m.kernel_size[0] == m.kernel_size[1]\n",
        "                initial_weight = get_upsampling_weight(\n",
        "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
        "                m.weight.data.copy_(initial_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.relu1_1(self.conv1_1(h))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        h = self.pool3(h)\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        h = self.pool4(h)\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "\n",
        "        h = self.upscore(h)\n",
        "        h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]].contiguous()\n",
        "\n",
        "        return h"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TA1WxLkVOL4"
      },
      "source": [
        "class FCN16s(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=6):\n",
        "        super(FCN16s, self).__init__()\n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
        "\n",
        "        self.upscore2 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False)\n",
        "        self.upscore16 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 32, stride=16, bias=False)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.zero_()\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                assert m.kernel_size[0] == m.kernel_size[1]\n",
        "                initial_weight = get_upsampling_weight(\n",
        "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
        "                m.weight.data.copy_(initial_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.relu1_1(self.conv1_1(h))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        h = self.pool3(h)\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        h = self.pool4(h)\n",
        "        pool4 = h  # 1/16\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "        h = self.upscore2(h)\n",
        "        upscore2 = h  # 1/16\n",
        "\n",
        "        h = self.score_pool4(pool4)\n",
        "        h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
        "        score_pool4c = h  # 1/16\n",
        "\n",
        "        h = upscore2 + score_pool4c\n",
        "\n",
        "        h = self.upscore16(h)\n",
        "        h = h[:, :, 27:27 + x.size()[2], 27:27 + x.size()[3]].contiguous()\n",
        "\n",
        "        return h"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4Z03NF2VOJ9"
      },
      "source": [
        "class FCN8s(nn.Module):\n",
        "\n",
        "    def __init__(self, n_class=6):\n",
        "        super(FCN8s, self).__init__()\n",
        "        # conv1\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
        "\n",
        "        # conv2\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
        "\n",
        "        # conv3\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
        "\n",
        "        # conv4\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
        "\n",
        "        # conv5\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
        "\n",
        "        # fc6\n",
        "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.drop6 = nn.Dropout2d()\n",
        "\n",
        "        # fc7\n",
        "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.drop7 = nn.Dropout2d()\n",
        "\n",
        "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
        "        self.score_pool3 = nn.Conv2d(256, n_class, 1)\n",
        "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
        "\n",
        "        self.upscore2 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False)\n",
        "        self.upscore8 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 16, stride=8, bias=False)\n",
        "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
        "            n_class, n_class, 4, stride=2, bias=False)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                m.weight.data.zero_()\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                assert m.kernel_size[0] == m.kernel_size[1]\n",
        "                initial_weight = get_upsampling_weight(\n",
        "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
        "                m.weight.data.copy_(initial_weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x\n",
        "        h = self.relu1_1(self.conv1_1(h))\n",
        "        h = self.relu1_2(self.conv1_2(h))\n",
        "        h = self.pool1(h)\n",
        "\n",
        "        h = self.relu2_1(self.conv2_1(h))\n",
        "        h = self.relu2_2(self.conv2_2(h))\n",
        "        h = self.pool2(h)\n",
        "\n",
        "        h = self.relu3_1(self.conv3_1(h))\n",
        "        h = self.relu3_2(self.conv3_2(h))\n",
        "        h = self.relu3_3(self.conv3_3(h))\n",
        "        h = self.pool3(h)\n",
        "        pool3 = h  # 1/8\n",
        "\n",
        "        h = self.relu4_1(self.conv4_1(h))\n",
        "        h = self.relu4_2(self.conv4_2(h))\n",
        "        h = self.relu4_3(self.conv4_3(h))\n",
        "        h = self.pool4(h)\n",
        "        pool4 = h  # 1/16\n",
        "\n",
        "        h = self.relu5_1(self.conv5_1(h))\n",
        "        h = self.relu5_2(self.conv5_2(h))\n",
        "        h = self.relu5_3(self.conv5_3(h))\n",
        "        h = self.pool5(h)\n",
        "\n",
        "        h = self.relu6(self.fc6(h))\n",
        "        h = self.drop6(h)\n",
        "\n",
        "        h = self.relu7(self.fc7(h))\n",
        "        h = self.drop7(h)\n",
        "\n",
        "        h = self.score_fr(h)\n",
        "        h = self.upscore2(h)\n",
        "        upscore2 = h  # 1/16\n",
        "\n",
        "        h = self.score_pool4(pool4)\n",
        "        h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
        "        score_pool4c = h  # 1/16\n",
        "\n",
        "        h = upscore2 + score_pool4c  # 1/16\n",
        "        h = self.upscore_pool4(h)\n",
        "        upscore_pool4 = h  # 1/8\n",
        "\n",
        "        h = self.score_pool3(pool3)\n",
        "        h = h[:, :, 9:9 + upscore_pool4.size()[2], 9:9 + upscore_pool4.size()[3]]\n",
        "        score_pool3c = h  # 1/8\n",
        "\n",
        "        h = upscore_pool4 + score_pool3c  # 1/8\n",
        "\n",
        "        h = self.upscore8(h)\n",
        "        h = h[:, :, 31:31 + x.size()[2], 31:31 + x.size()[3]].contiguous()\n",
        "\n",
        "        return h"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBeFMHMvVOIL",
        "outputId": "24fddcf1-68e0-48cc-f475-29c9522d0f5e"
      },
      "source": [
        "# model = load_segmentation_models('fcn8', 6)\n",
        "# for image, mask in train_loader:\n",
        "#     y = model(image)\n",
        "#     print(y.shape)\n",
        "#     break"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RbhMop1VOGH"
      },
      "source": [
        "class CBR(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride, padding):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=k_size, stride=stride, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(num_features=c_out)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CR(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_out, k_size, stride, padding):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=c_in, out_channels=c_out, kernel_size=k_size, stride=stride, padding=padding)\n",
        "        self.act = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        # Contracting path\n",
        "        self.encoder_1_1 = CR(3, 64, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_1_2 = CR(64, 64, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_1_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_2_1 = CR(64, 128, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_2_2 = CR(128, 128, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_2_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_3_1 = CR(128, 256, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_3_2 = CR(256, 256, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_3_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_4_1 = CR(256, 512, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_4_2 = CR(512, 512, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_4_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_5_1 = CR(512, 1024, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_5_2 = CR(1024, 1024, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Expansive path\n",
        "        self.decoder_1_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_1_2 = CR(1024, 512, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_1_3 = CR(512, 512, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_2_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_2_2 = CR(512, 256, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_2_3 = CR(256, 256, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_3_1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_3_2 = CR(256, 128, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_3_3 = CR(128, 128, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_4_1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_4_2 = CR(128, 64, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_4_3 = CR(64, 64, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.pointwise_conv = nn.Conv2d(64, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        \n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Contracting path\n",
        "        enc_1_1 = self.encoder_1_1(x)\n",
        "        enc_1_2 = self.encoder_1_2(enc_1_1)\n",
        "        pool_1 = self.encoder_1_3(enc_1_2)\n",
        "\n",
        "        enc_2_1 = self.encoder_2_1(pool_1)\n",
        "        enc_2_2 = self.encoder_2_2(enc_2_1)\n",
        "        pool_2 = self.encoder_2_3(enc_2_2)\n",
        "\n",
        "        enc_3_1 = self.encoder_3_1(pool_2)\n",
        "        enc_3_2 = self.encoder_3_2(enc_3_1)\n",
        "        pool_3 = self.encoder_3_3(enc_3_2)\n",
        "\n",
        "        enc_4_1 = self.encoder_4_1(pool_3)\n",
        "        enc_4_2 = self.encoder_4_2(enc_4_1)\n",
        "        pool_4 = self.encoder_4_3(enc_4_2)\n",
        "\n",
        "        enc_5_1 = self.encoder_5_1(pool_4)\n",
        "        enc_5_2 = self.encoder_5_2(enc_5_1)\n",
        "\n",
        "        # Expansive path\n",
        "        up_conv_1 = self.decoder_1_1(enc_5_2, output_size=enc_4_1.shape[2:])\n",
        "        dec_1_2 = self.decoder_1_2(torch.cat([enc_4_2, up_conv_1], dim=1))\n",
        "        dec_1_3 = self.decoder_1_3(dec_1_2)\n",
        "\n",
        "        up_conv_2 = self.decoder_2_1(dec_1_3, output_size=enc_3_1.shape[2:])\n",
        "        dec_2_2 = self.decoder_2_2(torch.cat([enc_3_2, up_conv_2], dim=1))\n",
        "        dec_2_3 = self.decoder_2_3(dec_2_2)\n",
        "\n",
        "        up_conv_3 = self.decoder_3_1(dec_2_3, output_size=enc_2_1.shape[2:])\n",
        "        dec_3_2 = self.decoder_3_2(torch.cat([enc_2_2, up_conv_3], dim=1))\n",
        "        dec_3_3 = self.decoder_3_3(dec_3_2)\n",
        "\n",
        "        up_conv_4 = self.decoder_4_1(dec_3_3, output_size=enc_1_1.shape[2:])\n",
        "        dec_4_2 = self.decoder_4_2(torch.cat([enc_1_2, up_conv_4], dim=1))\n",
        "        dec_4_3 = self.decoder_4_3(dec_4_2)\n",
        "        \n",
        "        out = self.pointwise_conv(dec_4_3)\n",
        "\n",
        "        return out\n",
        "\n",
        "class UNet_BN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Contracting path\n",
        "        self.encoder_1_1 = CBR(3, 64, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_1_2 = CBR(64, 64, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_1_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_2_1 = CBR(64, 128, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_2_2 = CBR(128, 128, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_2_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_3_1 = CBR(128, 256, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_3_2 = CBR(256, 256, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_3_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_4_1 = CBR(256, 512, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_4_2 = CBR(512, 512, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_4_3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.encoder_5_1 = CBR(512, 1024, k_size=3, stride=1, padding=1)\n",
        "        self.encoder_5_2 = CBR(1024, 1024, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Expansive path\n",
        "        self.decoder_1_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_1_2 = CBR(1024, 512, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_1_3 = CBR(512, 512, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_2_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_2_2 = CBR(512, 256, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_2_3 = CBR(256, 256, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_3_1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_3_2 = CBR(256, 128, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_3_3 = CBR(128, 128, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.decoder_4_1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2, padding=0)\n",
        "        self.decoder_4_2 = CBR(128, 64, k_size=3, stride=1, padding=1)\n",
        "        self.decoder_4_3 = CBR(64, 64, k_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.pointwise_conv = nn.Conv2d(64, num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        \n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "            if isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Contracting path\n",
        "        enc_1_1 = self.encoder_1_1(x)\n",
        "        enc_1_2 = self.encoder_1_2(enc_1_1)\n",
        "        pool_1 = self.encoder_1_3(enc_1_2)\n",
        "\n",
        "        enc_2_1 = self.encoder_2_1(pool_1)\n",
        "        enc_2_2 = self.encoder_2_2(enc_2_1)\n",
        "        pool_2 = self.encoder_2_3(enc_2_2)\n",
        "\n",
        "        enc_3_1 = self.encoder_3_1(pool_2)\n",
        "        enc_3_2 = self.encoder_3_2(enc_3_1)\n",
        "        pool_3 = self.encoder_3_3(enc_3_2)\n",
        "\n",
        "        enc_4_1 = self.encoder_4_1(pool_3)\n",
        "        enc_4_2 = self.encoder_4_2(enc_4_1)\n",
        "        pool_4 = self.encoder_4_3(enc_4_2)\n",
        "\n",
        "        enc_5_1 = self.encoder_5_1(pool_4)\n",
        "        enc_5_2 = self.encoder_5_2(enc_5_1)\n",
        "\n",
        "        # Expansive path\n",
        "        up_conv_1 = self.decoder_1_1(enc_5_2, output_size=enc_4_1.shape[2:])\n",
        "        dec_1_2 = self.decoder_1_2(torch.cat([enc_4_2, up_conv_1], dim=1))\n",
        "        dec_1_3 = self.decoder_1_3(dec_1_2)\n",
        "\n",
        "        up_conv_2 = self.decoder_2_1(dec_1_3, output_size=enc_3_1.shape[2:])\n",
        "        dec_2_2 = self.decoder_2_2(torch.cat([enc_3_2, up_conv_2], dim=1))\n",
        "        dec_2_3 = self.decoder_2_3(dec_2_2)\n",
        "\n",
        "        up_conv_3 = self.decoder_3_1(dec_2_3, output_size=enc_2_1.shape[2:])\n",
        "        dec_3_2 = self.decoder_3_2(torch.cat([enc_2_2, up_conv_3], dim=1))\n",
        "        dec_3_3 = self.decoder_3_3(dec_3_2)\n",
        "\n",
        "        up_conv_4 = self.decoder_4_1(dec_3_3, output_size=enc_1_1.shape[2:])\n",
        "        dec_4_2 = self.decoder_4_2(torch.cat([enc_1_2, up_conv_4], dim=1))\n",
        "        dec_4_3 = self.decoder_4_3(dec_4_2)\n",
        "        \n",
        "        out = self.pointwise_conv(dec_4_3)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def unet(num_classes, use_batchnorm=False):\n",
        "    if use_batchnorm:\n",
        "        return UNet_BN(num_classes)\n",
        "    else:\n",
        "        return UNet(num_classes)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7PHL_SBVOBh"
      },
      "source": [
        "class SegNet(nn.Module):\n",
        "    \"\"\"SegNet: A Deep Convolutional Encoder-Decoder Architecture for\n",
        "    Image Segmentation. https://arxiv.org/abs/1511.00561\n",
        "    See https://github.com/alexgkendall/SegNet-Tutorial for original models.\n",
        "    Args:\n",
        "        num_classes (int): number of classes to segment\n",
        "        n_init_features (int): number of input features in the fist convolution\n",
        "        drop_rate (float): dropout rate of each encoder/decoder module\n",
        "        filter_config (list of 5 ints): number of output features at each level\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes, n_init_features=3, drop_rate=0.5,\n",
        "                 filter_config=(64, 128, 256, 512, 512)):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        self.encoders = nn.ModuleList()\n",
        "        self.decoders = nn.ModuleList()\n",
        "        # setup number of conv-bn-relu blocks per module and number of filters\n",
        "        encoder_n_layers = (2, 2, 3, 3, 3)\n",
        "        encoder_filter_config = (n_init_features,) + filter_config\n",
        "        decoder_n_layers = (3, 3, 3, 2, 1)\n",
        "        decoder_filter_config = filter_config[::-1] + (filter_config[0],)\n",
        "\n",
        "        for i in range(0, 5):\n",
        "            # encoder architecture\n",
        "            self.encoders.append(_Encoder(encoder_filter_config[i],\n",
        "                                          encoder_filter_config[i + 1],\n",
        "                                          encoder_n_layers[i], drop_rate))\n",
        "\n",
        "            # decoder architecture\n",
        "            self.decoders.append(_Decoder(decoder_filter_config[i],\n",
        "                                          decoder_filter_config[i + 1],\n",
        "                                          decoder_n_layers[i], drop_rate))\n",
        "\n",
        "        # final classifier (equivalent to a fully connected layer)\n",
        "        self.classifier = nn.Conv2d(filter_config[0], num_classes, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        indices = []\n",
        "        unpool_sizes = []\n",
        "        feat = x\n",
        "\n",
        "        # encoder path, keep track of pooling indices and features size\n",
        "        for i in range(0, 5):\n",
        "            (feat, ind), size = self.encoders[i](feat)\n",
        "            indices.append(ind)\n",
        "            unpool_sizes.append(size)\n",
        "\n",
        "        # decoder path, upsampling with corresponding indices and size\n",
        "        for i in range(0, 5):\n",
        "            feat = self.decoders[i](feat, indices[4 - i], unpool_sizes[4 - i])\n",
        "\n",
        "        return self.classifier(feat)\n",
        "\n",
        "\n",
        "class _Encoder(nn.Module):\n",
        "    def __init__(self, n_in_feat, n_out_feat, n_blocks=2, drop_rate=0.5):\n",
        "        \"\"\"Encoder layer follows VGG rules + keeps pooling indices\n",
        "        Args:\n",
        "            n_in_feat (int): number of input features\n",
        "            n_out_feat (int): number of output features\n",
        "            n_blocks (int): number of conv-batch-relu block inside the encoder\n",
        "            drop_rate (float): dropout rate to use\n",
        "        \"\"\"\n",
        "        super(_Encoder, self).__init__()\n",
        "\n",
        "        layers = [nn.Conv2d(n_in_feat, n_out_feat, 3, 1, 1),\n",
        "                  nn.BatchNorm2d(n_out_feat),\n",
        "                  nn.ReLU(inplace=True)]\n",
        "\n",
        "        if n_blocks > 1:\n",
        "            layers += [nn.Conv2d(n_out_feat, n_out_feat, 3, 1, 1),\n",
        "                       nn.BatchNorm2d(n_out_feat),\n",
        "                       nn.ReLU(inplace=True)]\n",
        "            if n_blocks == 3:\n",
        "                layers += [nn.Dropout(drop_rate)]\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        return F.max_pool2d(output, 2, 2, return_indices=True), output.size()\n",
        "\n",
        "\n",
        "class _Decoder(nn.Module):\n",
        "    \"\"\"Decoder layer decodes the features by unpooling with respect to\n",
        "    the pooling indices of the corresponding decoder part.\n",
        "    Args:\n",
        "        n_in_feat (int): number of input features\n",
        "        n_out_feat (int): number of output features\n",
        "        n_blocks (int): number of conv-batch-relu block inside the decoder\n",
        "        drop_rate (float): dropout rate to use\n",
        "    \"\"\"\n",
        "    def __init__(self, n_in_feat, n_out_feat, n_blocks=2, drop_rate=0.5):\n",
        "        super(_Decoder, self).__init__()\n",
        "\n",
        "        layers = [nn.Conv2d(n_in_feat, n_in_feat, 3, 1, 1),\n",
        "                  nn.BatchNorm2d(n_in_feat),\n",
        "                  nn.ReLU(inplace=True)]\n",
        "\n",
        "        if n_blocks > 1:\n",
        "            layers += [nn.Conv2d(n_in_feat, n_out_feat, 3, 1, 1),\n",
        "                       nn.BatchNorm2d(n_out_feat),\n",
        "                       nn.ReLU(inplace=True)]\n",
        "            if n_blocks == 3:\n",
        "                layers += [nn.Dropout(drop_rate)]\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, indices, size):\n",
        "        unpooled = F.max_unpool2d(x, indices, 2, 2, 0, size)\n",
        "        return self.features(unpooled)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHh6jbLnVv44"
      },
      "source": [
        "# Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXwMQYqkVxib"
      },
      "source": [
        "class Evaluator(object):\n",
        "    def __init__(self, num_class):\n",
        "        self.num_class = num_class\n",
        "        self.confusion_matrix = np.zeros((self.num_class,) * 2)\n",
        "\n",
        "    def _generate_matrix(self, gt_image, pred_image):\n",
        "        mask = (gt_image >= 0) & (gt_image < self.num_class)\n",
        "        label = self.num_class * gt_image[mask].astype('int') + pred_image[mask]\n",
        "        count = np.bincount(label, minlength=self.num_class**2)\n",
        "        confusion_matrix = count.reshape(self.num_class, self.num_class)\n",
        "        return confusion_matrix\n",
        "\n",
        "    def Pixel_Accuracy(self):\n",
        "        Acc = np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
        "        return Acc\n",
        "\n",
        "    def Pixel_Accuracy_Class(self):\n",
        "        Acc = np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
        "        Acc = np.nanmean(Acc)\n",
        "        return Acc\n",
        "\n",
        "    def Mean_Intersection_over_Union(self):\n",
        "        MIoU = np.diag(self.confusion_matrix) / (\n",
        "               np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0)\n",
        "               - np.diag(self.confusion_matrix))\n",
        "        MIoU = np.nanmean(MIoU)\n",
        "\n",
        "        return MIoU\n",
        "\n",
        "    def Frequency_Weighted_Intersection_over_Union(self):\n",
        "        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n",
        "        iu = np.diag(self.confusion_matrix) / (\n",
        "                    np.sum(self.confusion_matrix, axis=1) + np.sum(self.confusion_matrix, axis=0) -\n",
        "                    np.diag(self.confusion_matrix))\n",
        "\n",
        "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "        return FWIoU\n",
        "\n",
        "    def add_batch(self, gt_image, pred_image):\n",
        "        assert gt_image.shape == pred_image.shape\n",
        "        self.confusion_matrix += self._generate_matrix(gt_image, pred_image)\n",
        "\n",
        "    def reset(self):\n",
        "        self.confusion_matrix = np.zeros((self.num_class,) * 2)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrbtHvkxV5dg"
      },
      "source": [
        "# Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lQ4IiUKVxgw"
      },
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import argparse\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTK_lMpNVxe-"
      },
      "source": [
        "def segmentation_parser():\n",
        "    parser = argparse.ArgumentParser(description='PyTorch Semantic Segmentation Training')\n",
        "\n",
        "    # data loader\n",
        "    parser.add_argument('--valid_ratio', type=float, default=0.5, help='validation set ratio')\n",
        "    parser.add_argument('--shuffle_dataset', type=bool, default=True)\n",
        "\n",
        "    # model type selection\n",
        "    parser.add_argument('--n_class', type=int, default=7, help='# of class')\n",
        "    parser.add_argument('--model_name', type=str, default=\"segnet\",\n",
        "                        choices=[\"fcn8\", \"fcn16\", \"fcn32\", \"unet\", \"segnet\"],\n",
        "                        help='segmentation models')\n",
        "\n",
        "    # training hyperparameters\n",
        "    parser.add_argument('--epochs', type=int, default=5,\n",
        "                        help='number of epochs to train (default: auto)')\n",
        "    parser.add_argument('--batch-size', type=int, default=2,\n",
        "                        metavar='N', help='input batch size for training (default: auto)')\n",
        "    parser.add_argument('--test-batch-size', type=int, default=1,\n",
        "                        metavar='N', help='input batch size for training (default: auto)')\n",
        "\n",
        "    # optimizer parameters\n",
        "    parser.add_argument('--lr', type=float, default=1e-3,\n",
        "                        help='learning rate (default: auto)')\n",
        "    parser.add_argument('--weight-decay', type=float, default=1e-2,\n",
        "                        metavar='M', help='weight decay (default: 5e-4)')\n",
        "    parser.add_argument('--momentum', type=float, default=0.9)\n",
        "\n",
        "    # cuda, seed and logging\n",
        "    parser.add_argument('--seed', type=int, default=2021,\n",
        "                        help='random seed (default: 1)')\n",
        "    parser.add_argument('--results_dir', type=str, default='./results')\n",
        "\n",
        "    return parser"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M59cQP6VxdQ",
        "outputId": "7f799b55-7b82-41b3-c512-3e2b5331dd64"
      },
      "source": [
        "# define parser\n",
        "parser = segmentation_parser()\n",
        "args = parser.parse_args('')\n",
        "args.cuda = torch.device('cuda:0')\n",
        "args.model_name = \"fcn8\"\n",
        "print(args)\n",
        "# reproducibility\n",
        "random_seed = args.seed\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=2, cuda=device(type='cuda', index=0), epochs=5, lr=0.001, model_name='fcn8', momentum=0.9, n_class=7, results_dir='./results', seed=2021, shuffle_dataset=True, test_batch_size=1, valid_ratio=0.5, weight_decay=0.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhRNj6MaWWoa"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKBPq-OuVrtK"
      },
      "source": [
        "# define data loader\n",
        "train_loader, valid_loader, test_loader = make_data_loaders(args)\n",
        "\n",
        "# define model\n",
        "model = load_segmentation_models(model_name=args.model_name, num_class=args.n_class)\n",
        "model.to(args.cuda)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def train(net, data_loader, train_optimizer, epoch, args):\n",
        "    net.train()\n",
        "\n",
        "    total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader, desc=\"train steps\", total=len(data_loader))\n",
        "    for inputs, targets in train_bar:\n",
        "        targets = targets.squeeze(1).long()\n",
        "        inputs, targets = inputs.to(args.cuda), targets.to(args.cuda)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        train_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_optimizer.step()\n",
        "\n",
        "        total_num += data_loader.batch_size\n",
        "        total_loss += loss.item() * data_loader.batch_size\n",
        "        train_bar.set_description('Train Epoch: [{}/{}], lr: {:.6f}, Loss: {:.4f}'.format(epoch, args.epochs, get_lr(train_optimizer), total_loss / total_num))\n",
        "\n",
        "    return total_loss / total_num\n",
        "\n",
        "\n",
        "def validation(net, data_loader, evaluator, epoch, args):\n",
        "    net.eval()\n",
        "    evaluator.reset()\n",
        "\n",
        "    total_loss, total_num, valid_bar = 0.0, 0, tqdm(data_loader, desc=\"validation steps\", total=len(data_loader))\n",
        "    for inputs, targets in valid_bar:\n",
        "        targets = targets.squeeze(1).long()\n",
        "        inputs, targets = inputs.to(args.cuda), targets.to(args.cuda)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        targets = targets.cpu().numpy()\n",
        "        _, predict = torch.max(outputs, dim=1)\n",
        "        pred = predict.cpu().numpy()\n",
        "\n",
        "        evaluator.add_batch(targets, pred)\n",
        "\n",
        "        Acc = evaluator.Pixel_Accuracy()\n",
        "        # Acc_class = evaluator.Pixel_Accuracy_Class()\n",
        "        mIoU = evaluator.Mean_Intersection_over_Union()\n",
        "        # FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
        "\n",
        "        total_num += data_loader.batch_size\n",
        "        total_loss += loss.item() * data_loader.batch_size\n",
        "        valid_bar.set_description('Valid Epoch: [{}/{}], Loss: {:.4f}, Acc: {:.3f}, mIoU: {:.3f}'.format(epoch,\n",
        "                                                                                                         args.epochs,\n",
        "                                                                                                         total_loss / total_num,\n",
        "                                                                                                         Acc,\n",
        "                                                                                                         mIoU))\n",
        "\n",
        "    return total_loss / total_num, Acc, mIoU\n",
        "\n",
        "\n",
        "def test(net, data_loader, evaluator, epoch, args):\n",
        "    net.eval()\n",
        "    evaluator.reset()\n",
        "\n",
        "    total_loss, total_num, test_bar = 0.0, 0, tqdm(data_loader, desc=\"test steps\", total=len(data_loader))\n",
        "    for inputs, targets in test_bar:\n",
        "        targets = targets.squeeze(1).long()\n",
        "        inputs, targets = inputs.to(args.cuda), targets.to(args.cuda)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        targets = targets.cpu().numpy()\n",
        "        _, predict = torch.max(outputs, dim=1)\n",
        "        pred = predict.cpu().numpy()\n",
        "\n",
        "        evaluator.add_batch(targets, pred)\n",
        "\n",
        "        Acc = evaluator.Pixel_Accuracy()\n",
        "        # Acc_class = evaluator.Pixel_Accuracy_Class()\n",
        "        mIoU = evaluator.Mean_Intersection_over_Union()\n",
        "        # FWIoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
        "\n",
        "        total_num += data_loader.batch_size\n",
        "        test_bar.set_description('Test Epoch: [{}/{}], Acc: {:.3f}, mIoU: {:.3f}'.format(epoch,\n",
        "                                                                                          args.epochs,\n",
        "                                                                                          Acc,\n",
        "                                                                                          mIoU))\n",
        "\n",
        "    return Acc, mIoU"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRPhH6t-VN2V",
        "outputId": "02ec808e-e7b9-4a22-d052-463b9d34363e"
      },
      "source": [
        "#%% training setting\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "evaluator = Evaluator(num_class=args.n_class)\n",
        "best_pred = -np.inf\n",
        "\n",
        "#%% logging\n",
        "results = {'train_loss': [], 'valid_loss':[], 'valid_acc':[], 'valid_mIoU':[], 'test_acc':[], 'test_mIoU':[]}\n",
        "\n",
        "if not os.path.exists(args.results_dir):\n",
        "    os.makedirs(args.results_dir, exist_ok=True)\n",
        "\n",
        "#%% training run !\n",
        "epoch_start = 1\n",
        "\n",
        "for epoch in range(epoch_start, args.epochs+1):\n",
        "    # train\n",
        "    train_loss = train(model, train_loader, optimizer, epoch, args)\n",
        "    results['train_loss'].append(train_loss)\n",
        "\n",
        "    valid_loss, valid_acc, valid_mIoU = validation(model, valid_loader, evaluator, epoch, args)\n",
        "    results['valid_loss'].append(valid_loss)\n",
        "    results['valid_acc'].append(valid_acc)\n",
        "    results['valid_mIoU'].append(valid_mIoU)\n",
        "\n",
        "    if valid_mIoU > best_pred:\n",
        "        test_acc, test_mIoU = test(model, test_loader, evaluator, epoch, args)\n",
        "\n",
        "        torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict()},\n",
        "                   args.results_dir + '/model_last.pth')\n",
        "\n",
        "        best_pred = valid_mIoU\n",
        "\n",
        "    results['test_acc'].append(test_acc)\n",
        "    results['test_mIoU'].append(test_mIoU)\n",
        "\n",
        "    # save statistics\n",
        "    data_frame = pd.DataFrame(data=results, index=range(epoch_start, epoch + 1))\n",
        "    data_frame.to_csv(args.results_dir + '/log.csv', index_label='epoch')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch: [1/5], lr: 0.001000, Loss: 1.9459: 100%|| 1/1 [00:03<00:00,  3.66s/it]\n",
            "Valid Epoch: [1/5], Loss: 1.9421, Acc: 0.774, mIoU: 0.111: 100%|| 1/1 [00:01<00:00,  1.76s/it]\n",
            "Test Epoch: [1/5], Acc: 0.796, mIoU: 0.114: 100%|| 1/1 [00:01<00:00,  1.63s/it]\n",
            "Train Epoch: [2/5], lr: 0.001000, Loss: 1.9417: 100%|| 1/1 [00:02<00:00,  2.10s/it]\n",
            "Valid Epoch: [2/5], Loss: 1.9381, Acc: 0.774, mIoU: 0.111: 100%|| 1/1 [00:00<00:00,  1.61it/s]\n",
            "Train Epoch: [3/5], lr: 0.001000, Loss: 1.9372: 100%|| 1/1 [00:01<00:00,  1.95s/it]\n",
            "Valid Epoch: [3/5], Loss: 1.9336, Acc: 0.774, mIoU: 0.111: 100%|| 1/1 [00:00<00:00,  1.62it/s]\n",
            "Train Epoch: [4/5], lr: 0.001000, Loss: 1.9323: 100%|| 1/1 [00:01<00:00,  1.95s/it]\n",
            "Valid Epoch: [4/5], Loss: 1.9287, Acc: 0.774, mIoU: 0.111: 100%|| 1/1 [00:00<00:00,  1.60it/s]\n",
            "Train Epoch: [5/5], lr: 0.001000, Loss: 1.9268: 100%|| 1/1 [00:01<00:00,  1.96s/it]\n",
            "Valid Epoch: [5/5], Loss: 1.9234, Acc: 0.774, mIoU: 0.111: 100%|| 1/1 [00:00<00:00,  1.61it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkmUSyPWYk3s",
        "outputId": "76ee1b28-e10d-4c20-d1db-2a8cdeee9fa7"
      },
      "source": [
        "data = pd.read_csv('./results/log.csv')\n",
        "print(data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   epoch  train_loss  valid_loss  valid_acc  valid_mIoU  test_acc  test_mIoU\n",
            "0      1    1.945908    1.942139   0.774485    0.110641  0.795927   0.113704\n",
            "1      2    1.941730    1.938060   0.774485    0.110641  0.795927   0.113704\n",
            "2      3    1.937205    1.933599   0.774485    0.110641  0.795927   0.113704\n",
            "3      4    1.932259    1.928710   0.774485    0.110641  0.795927   0.113704\n",
            "4      5    1.926837    1.923370   0.774485    0.110641  0.795927   0.113704\n"
          ]
        }
      ]
    }
  ]
}